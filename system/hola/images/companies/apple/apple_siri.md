LLM focused
-----------

fine tuned adapters
very close to foundation models
approaches 
develop the right 
hong - responsible high dialogue response
experiences that are built
dialogue generated by the model
pre-training
prompt engineering

RAG based
---------
look up the relevant instruction
in the making

Host of different technologies

Innovation

Happens cross polinate

Prompt engineering

Post training efforts

Deployment system in 

Anticipate future needs
- RAG
- extensions multimodal
- graph nn

Cross-eco system
- event monitoring

Competitive gap
- strategy advocate for a small iterative feature

Resource optimization
- ambitious goals
- low-effort initiative

Driving innovation
- BAG - berkeley automation generation

Cross-Functional
Enginering / design / business

Mentorship & elevating others
- 

Ownership
- full ownership
- heavy time

Adaptability
- had to pivot
- rapidly changing
- cannot get this measurement done

Senior 

Response relation modeling
Closely with design
Directly related - apple's design intent

- quality we have a lot of smarter people in the team
  speed efficiency 
  thinking out of the box
  delivery

- not easy
  plow through that bring lot of energy

- apple 
  - high priority it is that important
  - if something is important 
  - v1 and v2

---
hong yu teams
stuart bowers

08/01/25

Core AI within seri
what parameter and what response
LLM based
figure moderize series how to built this systems
maintain context correct in conversational
wealth of knowledge
special touh
everything that want to know on internet
can compose text
many more actions
calednar
text mssae
theorritical can do 
a lot of things
talk hands free on the phone
reminder
order my favorite food

privacy capturing log
bet yes some value on the table
small percent opt in data
often 
simluate that we care about
on-device search
on device search
out of distribution

optimization problem
interesting property
in context learning

not have enough context
context
---

Roman and Chung director of ML Platforms
